{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Introduction Homework\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. Downloading the data\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"**Green** Taxi Trip Records\", we'll use \"**Yellow** Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2023.\n",
    "\n",
    "Read the data for January. How many columns are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jan 2023: 19, feb 2023: 19.\n"
     ]
    }
   ],
   "source": [
    "df_jan_2023 = pd.read_parquet('../../data/yellow_tripdata_2023-01.parquet')\n",
    "df_feb_2023 = pd.read_parquet('../../data/yellow_tripdata_2023-02.parquet')\n",
    "\n",
    "print(f\"jan 2023: {len(df_jan_2023.columns)}, feb 2023: {len(df_feb_2023.columns)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Computing duration\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the standard deviation of the trips duration in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.59\n"
     ]
    }
   ],
   "source": [
    "df_jan_2023['duration'] = df_jan_2023.tpep_dropoff_datetime - df_jan_2023.tpep_pickup_datetime\n",
    "df_jan_2023.duration = df_jan_2023.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "df_feb_2023['duration'] = df_feb_2023.tpep_dropoff_datetime - df_feb_2023.tpep_pickup_datetime\n",
    "df_feb_2023.duration = df_feb_2023.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "std_dev = df_jan_2023['duration'].std()\n",
    "\n",
    "print(np.round(std_dev, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. Dropping outliers\n",
    "Next, we need to check the distribution of the `duration` variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9812202822125979\n"
     ]
    }
   ],
   "source": [
    "# filter the DataFrame to remove outliers\n",
    "df_jan_filtered = df_jan_2023[(df_jan_2023['duration'] >= 1) & (df_jan_2023['duration'] <= 60)]\n",
    "df_feb_filtered = df_feb_2023[(df_feb_2023['duration'] >= 1) & (df_feb_2023['duration'] <= 60)]\n",
    "\n",
    "# calculate the fraction of the records left\n",
    "fraction_left = len(df_jan_filtered) / len(df_jan_2023)\n",
    "\n",
    "print(fraction_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4. One-hot encoding\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will \n",
    "  label encode them)\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dimensionality of the matrix is: 515\n"
     ]
    }
   ],
   "source": [
    "# convert the dataframe to a list of dictionaries\n",
    "train_data_dict = df_jan_filtered[['PULocationID', 'DOLocationID']].astype(str).to_dict('records')\n",
    "\n",
    "# initialize the DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "\n",
    "# fit and transform the data\n",
    "feature_matrix = vec.fit_transform(train_data_dict)\n",
    "\n",
    "print(f\"the dimensionality of the matrix is: {feature_matrix.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. One-hot encoding\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters \n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RMSE on the training data is: 7.649261936284003\n"
     ]
    }
   ],
   "source": [
    "# initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit the model on the feature matrix and the target variable\n",
    "model.fit(feature_matrix, df_jan_filtered['duration'])\n",
    "\n",
    "# predict the target variable on the training data\n",
    "train_preds = model.predict(feature_matrix)\n",
    "\n",
    "# calculate the RMSE on the training data\n",
    "rmse_train = np.sqrt(mean_squared_error(df_jan_filtered['duration'], train_preds))\n",
    "\n",
    "print(f\"the RMSE on the training data is: {rmse_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6. Evaluating the model\n",
    "Now let's apply this model to the validation dataset (February 2023). \n",
    "\n",
    "What's the RMSE on validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RMSE on the validation data is: 7.811818654341152\n"
     ]
    }
   ],
   "source": [
    "# convert the validation dataframe to a list of dictionaries\n",
    "val_data_dict = df_feb_filtered[['PULocationID', 'DOLocationID']].astype(str).to_dict('records')\n",
    "\n",
    "# transform the validation data using the same DictVectorizer\n",
    "val_feature_matrix = vec.transform(val_data_dict)\n",
    "\n",
    "# predict the target variable on the validation data\n",
    "val_preds = model.predict(val_feature_matrix)\n",
    "\n",
    "# calculate the RMSE on the validation data\n",
    "rmse_val = np.sqrt(mean_squared_error(df_feb_filtered['duration'], val_preds))\n",
    "\n",
    "print(f\"the RMSE on the validation data is: {rmse_val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
